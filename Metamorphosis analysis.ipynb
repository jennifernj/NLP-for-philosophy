{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Franz Kafka's _The Metamorphosis_ with NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kafka's _Metamorphosis_ is commonly interpreted by humans as giving insights into the meaning of personal identity\n",
    "* The conclusions that we can draw from texts are limited by our uniquely human preconceptions and rhetorical weaknesses\n",
    "* Guiding question: What happens when computers read philosophy? That is, if we apply machine learning and linguistic approaches from natural language processing (NLP) to analyzing _The Metamorphosis_, how will the results support or contrast with our human reading?\n",
    "* Read on to see what computers think about Kafka..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import random\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text is sourced from Project Gutenberg (David Wyllie\n",
    " translation): http://www.gutenberg.org/files/5200/5200-h/5200-h.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"5200-h.txt\", \"r\")\n",
    "content = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean messy string into individual word tokens (includes punctuation and contraction fragments) with some regex magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "words = re.findall(r'\\w+', content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'he',\n",
       " 'flowed',\n",
       " 'as',\n",
       " 'but',\n",
       " 'the',\n",
       " 'violin',\n",
       " 'her',\n",
       " 't',\n",
       " 'not',\n",
       " 'and',\n",
       " 'and',\n",
       " 'know',\n",
       " 'seemed',\n",
       " 'one']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(words, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22383"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many times each word occurs. Words are converted to lowercase to simplify things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_freqs(words):\n",
    "    freqs = {}\n",
    "    for word in words:\n",
    "        lower = word.lower()\n",
    "        if lower in freqs:\n",
    "            freqs[lower] += 1\n",
    "        else:\n",
    "            freqs[lower] = 1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs_dict = get_word_freqs(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dictionary of frequencies to a Pandas Series (nicer for lots of data). Note that there are far fewer unique than total words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2578"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freqs = pd.Series(word_freqs_dict)\n",
    "len(word_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 30 most frequently occurring words. By far the most common word is \"the\", which isn't surprising given its grammatical importance. In fact, most of these words aren't specific to _The Metamorphosis_. Interestingly, \"room\" appears more often even than generally common words \"be\" and \"could\", which suggests its significance in the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freqs['room']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the       1148\n",
       "to         753\n",
       "and        642\n",
       "he         590\n",
       "his        550\n",
       "of         429\n",
       "was        409\n",
       "it         370\n",
       "had        352\n",
       "in         348\n",
       "that       345\n",
       "gregor     298\n",
       "a          285\n",
       "as         242\n",
       "she        200\n",
       "with       199\n",
       "s          194\n",
       "him        188\n",
       "her        187\n",
       "would      187\n",
       "not        176\n",
       "but        171\n",
       "at         169\n",
       "for        166\n",
       "they       160\n",
       "on         152\n",
       "all        135\n",
       "room       131\n",
       "be         119\n",
       "could      119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freqs.nlargest(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since many of these words aren't very interesting, let's forget about them for now. These words are called <a href=\"https://en.wikipedia.org/wiki/Stop_words\" target=\"_blank\">stop words</a>, and the NLP library nltk conveniently includes a list of them so we can exclude them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some example stop words. Some may be word fragments due to how nltk parses words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['off', 'in', 'whom', \"needn't\", 'all', 'same', 'than', 'between', 'they', 'd']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "random.sample(stop_words, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay, that annoying \"the\" will be gone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'the' in stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude the stop words to create a new series with only the salient words. Now the most common words are actually meaningful! We see the main character names at the top: Gregor and his father, sister, and mother. \"Grete\" doesn't appear on the list at all, reflecting Kafka's tendency to describe her in relation to Gregor (i.e. \"his sister\") rather than as her own character. That \"room\" appears at the top along with the important people suggests that it could be considered a character in itself: It plays an essential role in Gregor's development as he lives out his bug life, more so than any of his family members. \"Time\" appearing frequently is indicative of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gregor     298\n",
       "would      187\n",
       "room       131\n",
       "could      119\n",
       "father     102\n",
       "sister     101\n",
       "mother      89\n",
       "door        87\n",
       "back        82\n",
       "even        80\n",
       "one         72\n",
       "way         62\n",
       "time        59\n",
       "said        51\n",
       "little      49\n",
       "first       44\n",
       "get         44\n",
       "still       44\n",
       "go          40\n",
       "made        40\n",
       "see         39\n",
       "without     39\n",
       "head        38\n",
       "like        38\n",
       "much        38\n",
       "chief       37\n",
       "clerk       37\n",
       "open        35\n",
       "samsa       34\n",
       "away        32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = [w for w in word_freqs.index if w in stop_words]\n",
    "word_freqs_salient = word_freqs.drop(to_drop)\n",
    "word_freqs_salient.nlargest(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gregor_indices = [i for i,x in enumerate(words) if x == 'Gregor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gregor_over_time = {}\n",
    "j=0\n",
    "for i in range(0, len(words), 100):\n",
    "    gregor_over_time[i] = 0\n",
    "    while j<len(gregor_indices) and gregor_indices[j] < i:\n",
    "        gregor_over_time[i] += 1\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gregor_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(gregor_over_time.keys()), list(gregor_over_time.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
