{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Franz Kafka's _The Metamorphosis_ with NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kafka's _Metamorphosis_ is commonly interpreted by humans as giving insights into the meaning of personal identity\n",
    "* The conclusions that we can draw from texts are limited by our uniquely human preconceptions and rhetorical weaknesses\n",
    "* Guiding question: What happens when computers read philosophy? That is, if we apply machine learning and linguistic approaches from natural language processing (NLP) to analyzing _The Metamorphosis_, how will the results support or contrast with our human reading?\n",
    "* Read on to see what computers think about Kafka..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import random\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text is sourced from Project Gutenberg (David Wyllie\n",
    " translation): http://www.gutenberg.org/files/5200/5200-h/5200-h.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"5200-h.txt\", \"r\")\n",
    "content = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean messy string into individual word tokens (includes punctuation and contraction fragments) with some nltk magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'room',\n",
       " 'Ah',\n",
       " 'his',\n",
       " 'the',\n",
       " 'out',\n",
       " 'darkness',\n",
       " 'but',\n",
       " 'his',\n",
       " 'not',\n",
       " 'Gregor',\n",
       " 'the',\n",
       " 'her',\n",
       " 'foot',\n",
       " 'how']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(words, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24973"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many times each word occurs. Words are converted to lowercase to simplify things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_freqs(words):\n",
    "    freqs = {}\n",
    "    for word in words:\n",
    "        if word in freqs:\n",
    "            freqs[word.lower()] += 1\n",
    "        else:\n",
    "            freqs[word.lower()] = 1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = get_word_freqs(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dictionary of frequencies to a Pandas Series (nicer for lots of data). Note that there are far fewer unique than total words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2591"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freqs = pd.Series(word_freqs)\n",
    "len(word_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 15 most frequently occurring words. By far the most common word is \"to\", which isn't surprising given its grammatical importance. In fact, most of these words aren't specific to _The Metamorphosis_. Interestingly, \"room\" appears more often even than \"that\" or \"have\", which suggests its significance in the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",         1293\n",
       "to         753\n",
       ".          700\n",
       "of         429\n",
       "'s         194\n",
       "him        188\n",
       "a          186\n",
       "not        177\n",
       "had        173\n",
       ";          170\n",
       "``         147\n",
       "room       131\n",
       "could      127\n",
       "''         115\n",
       "have       109\n",
       "would      105\n",
       "been       101\n",
       "sister     101\n",
       "be          89\n",
       "door        87\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freqs.nlargest(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since many of these words aren't very interesting, let's forget about them for now. These words are called <a href=\"https://en.wikipedia.org/wiki/Stop_words\" target=\"_blank\">stop words</a>, and the NLP library nltk conveniently includes a list of them so we can exclude them. Additionally, we'll filter out the punctuation and some contraction fragments that weren't included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some example stop words. Some may be word fragments due to how nltk parses words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['she', 'only', 'can', 'about', 'will', 'that', 'all', 'why', 'from', \"didn't\"]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = {',','.',';','``',\"''\",'?','!',\"'\",'(',')','-','...',':'}\n",
    "contraction_fragments = {\"'ave\",\"'d\",\"'ll\",\"'m\",\"'re\",\"'s\",\"'ve\"}\n",
    "stop_words.update(punctuation)\n",
    "stop_words.update(contraction_fragments)\n",
    "random.sample(stop_words, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay, that annoying \"to\" will be gone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'to' in stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude the stop words to create a new series with only the salient words. Now the most common words are actually meaningful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room       131\n",
       "could      127\n",
       "would      105\n",
       "sister     101\n",
       "door        87\n",
       "back        82\n",
       "n't         62\n",
       "way         62\n",
       "time        59\n",
       "said        51\n",
       "little      49\n",
       "get         44\n",
       "still       44\n",
       "even        43\n",
       "go          40\n",
       "made        40\n",
       "see         39\n",
       "without     39\n",
       "head        38\n",
       "much        38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = [w for w in word_freqs.index if w in stop_words]\n",
    "word_freqs_salient = word_freqs.drop(to_drop)\n",
    "word_freqs_salient.nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gregor_indices = [i for i,x in enumerate(words) if x == 'Gregor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gregor_over_time = {}\n",
    "j=0\n",
    "for i in range(0, len(words), 100):\n",
    "    gregor_over_time[i] = 0\n",
    "    while j<len(gregor_indices) and gregor_indices[j] < i:\n",
    "        gregor_over_time[i] += 1\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gregor_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(gregor_over_time.keys()), list(gregor_over_time.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
